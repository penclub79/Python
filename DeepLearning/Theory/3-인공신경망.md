# Deep-theory
# 컨볼루션 신경망 이론 및 구현
## 1.컨볼루션 뉴럴 네트워크(CNN)
### 1.1컨볼루션 뉴럴 네트워크 정의
#### CNN 소개
CNN은 2012년 세계적인 이미지 인식 경연 대회에서 세계 유수의 기관을 제치고 난데이없이 큰 격차로 캐나다의 토론토 대학의 슈퍼비전이 우승하게 되는데
그 때 사용된 방법이 CNN에 기반한다. 대회에서 고양이 이미지를 인식하는데 성공하면 되는 것 이었는데, 고양이 인식에는 '특징표현 학습'이라는 발명이
사용되었다. 컴퓨터 스스로가 특징표현을 만들어 내는 것이다.
 
Convolutional Neural Network(CNN)의 핵심은 사진을 학습한다는 것이다. Input으로 Label이 붙은 이미지 파일을 주고 수많은 이미지를 학습시켜 추후에
입력되었을 때 정확히 Label을 붙이는 것을 목적으로 한다. 예를 들어 강아지, 고양이, 새 등 여러 동물들의 이미지를 보여주고 새로운 강아지의 이미지를
입력하였을 때 학습된 컴퓨터가 해당 이미지를 강아지라고 판단하게 하는 것이 CNN의 목적이다. CNN은 생명체가 시각 정보를 처리하는 방식을 그대로 이용하고
있다. 우리가 무언가 사물을 볼 때 우리의 뇌는 사물을 부분적으로 인식하여 처리한 후 통합하여 하나의 이미지를 만들어낸다. CNN에서 역시 동일하다.
이미지를 한쪽 구석에서부터 읽어 나가 반대쪽 구석까지 차례차례 작은 이미지들로 읽어낸 후 각각을 처리하여 마지막에 통합하는 과정을 거친다.
![cnn](https://user-images.githubusercontent.com/40047360/44160016-0c157f80-a0f4-11e8-944f-9a78ae6ef074.png)

![cnn2](https://user-images.githubusercontent.com/40047360/44160148-72020700-a0f4-11e8-95a3-24c1b641d114.jpg)


### 1.2컨볼루션 뉴럴 네트워크 원리
#### 1.2.1컨볼루션이란 무엇인가?
정보를 섞는 것으로서 컨볼루션을 상상할 수 있다. 예를 들어 2개의 양동이에 어떤 정보가 가득 차 있고, 그것을 하나의 양동이에 쏟아 넣는다고 상상해보자.
각각의 양동이는 자신의 레시피를 가지고 있고, 그것을 통해 어떻게 정보들이 하나의 양동이에 섞이는지 알려준다. 즉, 컨볼루션은 2개의 정보가 서로 섞이는
순서가 있는 절차이다.

#### 1.2.2 Data(Input & Output)
우선CNN에 Input과 Output 데이터의 구조부터 살펴보면, Input은 이미지이다. 이미지의 구조는 3개의 숫자로 표현될 수 있다. 3차원 배열로, 
가로(width) x 세로(height) x 색깔(depth)의 의미를 지닌다. 가로와 세로는 말그대로 이미지의 크기를 나타내고 
세번째 항은 색이있는 이미지인지 여부를 나타낸다. 이 값이 1이라면 흑백 이미지, 3(RGB)이라면 컬러 이미지를 의미합니다. 
예를 들어 배열의 각 항들은 0~255 사이의 값을 가지고 있다. (x, y, 0)은 R의 정보를 (x, y, 1)은 G의 정보를 (x, y, 2)는 B의 정보를 담는 식이다.

Output은 해당 이미지가 어떤 Label을 가질 확률로 제시된다. FC layer에서는 Softmax classification을 이용하여 해당 이미지가 결국 어떤 Label을 가질
가능성이 높은지를 나타내주게 된다.

#### 1.2.3 Layer
- Convolutional layer(Conv)
Filter : CNN의 핵심이 되는 Layer이다. Conv는 이미지의 특성을 뽑아내는 Layer라고 할 수 있다. 아래 이미지는 Input된 이미지에 Filter를 이용하여
이미지의 특성을 뽑아내고 있다. 여기서 Filter를 Kernel이라고도 한다. Filter는 2차원 배열이다. 다만 R,G,B 정보를 담은 2차원 배열에서 각각 정보를
추출해야 하기 때문에 컬러 사진(Depth=3)에서는 Filter의 Depth 역시 3이 된다. Filter는 정확히 1칸씩 움직이며 정보를 추출해 낸다. 움직이는 칸수를
"Stride"라고 한다. 필터를 통해 추출해낸 숫자를 담은 배열을 "Activation map"이라고 부른다. Activation map의 개수는 사용한 Filter의 개수와 같다.
Filter는 이미지에서 정보를 추출하는 Feature identifier라고 하면 이해하기 쉬울 것 이다.

![cnn filter](https://user-images.githubusercontent.com/40047360/44272645-693a3e00-a278-11e8-9981-e610d8d9de2a.gif)
 
#### 1.2.4 CNN Example
다음과 같은 이미지가 Input으로 주어진다.
 ![cnn input image](https://user-images.githubusercontent.com/40047360/44272711-8969fd00-a278-11e8-9f05-04bc3cfeae4a.png)
 
왼쪽에서부터 Filter에 들어맞는 Feature가 있는지 검사
![cnn input image2](https://user-images.githubusercontent.com/40047360/44272753-a7cff880-a278-11e8-9e34-a77401232003.png)

Filter를 이용하여 이미지 정보(Feature) 추출
이미지 정보의 Feature을 추출하고 Receptive field에 Filter를 통해 계산했을 때, 계산값(6600)이 매우 크게 나온다. 이 말은 해당 Receptive field에
Filter에 담긴 정보가 존재한다는 뜻이다.
![cnn input image3](https://user-images.githubusercontent.com/40047360/44272924-1319ca80-a279-11e8-9126-53654d544a7f.png)

![cnn input image4](https://user-images.githubusercontent.com/40047360/44272875-f54c6580-a278-11e8-9c0d-4240ad54e95a.png)

이와 반대로 오른쪽 귀퉁이이 Receptive field에 Filter를 가져다 대봤더니 전혀 맞지 않는다. 다시 말해 오른쪽에는 Filter에 해당하는 정보가
없다는 것을 알 수 있다.
![cnn input image5](https://user-images.githubusercontent.com/40047360/44273040-5116ee80-a279-11e8-9d6a-c59448420c4f.png)

#### * Activation map(Feature map)
 * Filter를 사용하여 뽑아낸 숫자를 모아놓은 것을 Activation map이라고 한다. Activation map의 크기는 Filter의 크기와 Stride, 그리고 Padding에
   의해 결정된다. Filter를 통해 Convolution을 하여 만든 Activation map은 본래의 이미지 크기보다 작을 수밖에 없다.
 * Padding
   Filter를 사용하여 뽑아낸 숫자를 모아놓은 것을 Activation map이라고 한다. Activation map의 크기는 Filter의 크기와 Stride, 그리고 Padding에
   의해 결정된다. Filter를 통해 Convolution을 하여 만든 Activation map은 본래의 이미지 크기보다 작을 수밖에 없다.

#### 1.2.5 ReLU Layer
Nonlinearity를 부여하는 역할을 한다. Conv를 통과한 데이터는 덧셈, 곱셈으로만 이루어져 있다. Linear한 상태에서는 단순한 데이터 분류는 가능하지만
복잡한 데이터는 분류하기 힘들다. 따라서 CNN에서는 ReLU를 이용하여 Non-Linearity 속성을 부여하게 된다.
![default](https://user-images.githubusercontent.com/40047360/44273310-182b4980-a27a-11e8-894f-9ec717c21f57.png)

#### 1.2.6 Pooling Layer
Pooling layer는 Sub-Sampling을 목적으로 한다. Conv를 거친 데이터로부터 좋은 데이터를 한번 더 뽑아내겠다는 뜻이다.
![cnn filter](https://user-images.githubusercontent.com/40047360/44273601-d8b12d00-a27a-11e8-939e-2fe7748f40db.gif)

위 그림의 왼쪽 행렬은 Conv를 지난 Activation map이다. Activation map의 구획을 나누어 구획에서 대표 표본을 뽑아내는 것이 Pooling의 목적이다.
위 그림은 Pooling의 방법 중 하나인 Max Pooling을 보여주는 그림이다. Max pooling은 말 그대로 구획에서 가장 큰 값을 뽑아내는 방법으로
Average Pooling, L2-norm pooling 등이 있다고 하나 Max가 가장 좋은 방법이라고 한다. 이렇게 Pooling을 하면 크게 두 가지 효과를 얻을 수 있다.
첫째, 정말 꼭 필요한 데이터만 뽑아낼 수 있다는 것.
둘째, 그로 인해 데이터의 양이 작아진다는 것.
또한 원본 이미지에서 맥락에 맞지 않는 약간의 노이즈가 들어갈 경우에도 Pooling 과정을 거치면 노이즈를 일부 제거하고 데이터를 
학습시킬 수가 있게 된다.

#### 1.2.7 Fully Connected Layer(FC layer)
마지막 FC layer에서 이전까지의 정보를 모두 모아 Softmax classification을 통해 숫자를 예측하게 된다.
